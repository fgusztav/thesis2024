{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary python packages\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from google.cloud import vision, storage\n",
    "from google.oauth2 import service_account\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient, BlobClient, StandardBlobTier, PublicAccess\n",
    "import torch\n",
    "import io, json\n",
    "import cv2\n",
    "import os, shutil\n",
    "import random\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import psutil, gpustat, cpuinfo\n",
    "import PIL\n",
    "\n",
    "yolov5_model = YOLO('yolov5s.pt')\n",
    "yolov8_model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing the images and bbox data\n",
    "#dataset_name = \"Roboflow, Self Driving Car Image Dataset\"\n",
    "#original_image_folder = \"C:\\\\Users\\\\feren\\\\Downloads\\\\Self Driving Car.v2-fixed-large.coco\\\\OUTPUT\\\\train\"\n",
    "\n",
    "dataset_name = \"NuImages\"\n",
    "original_image_folder = \"C:\\\\Users\\\\feren\\\\Downloads\\\\nuimages_output\\\\train\"\n",
    "image_folder = \"temp_images\"\n",
    "output_path = \"G:\\\\My Drive\\\\Thesis2024\\\\output\"\n",
    "\n",
    "# Specify the desired Y-axis resolution\n",
    "desired_y_resolution = 900 #480 = VGA, 1200 = max\n",
    "\n",
    "inference_limit = 5\n",
    "request_time_limiter_ms = 300\n",
    "input_images_number = 5\n",
    "\n",
    "GOOGLE_MAX_RESULTS = 100 # no threshold setting\n",
    "REKOGNITION_CONFIDENCE_THRESHOLD = 0 # in percentage\n",
    "YOLOV5_CONFIDENCE_THRESHOLD = 0.0\n",
    "YOLOV8_CONFIDENCE_THRESHOLD = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change image resolution\n",
    "\n",
    "# Delete the image_folder and its contents if it exists\n",
    "if os.path.exists(image_folder):\n",
    "    shutil.rmtree(image_folder)\n",
    "# Create the image_folder directory if it doesn't exist\n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "# Iterate over the images in the original folder\n",
    "for image_file in os.listdir(original_image_folder):\n",
    "    # Check if the file is an image\n",
    "    if image_file.endswith(\".png\") or image_file.endswith(\".jpg\"):\n",
    "        # Open the image using PIL\n",
    "        image_path = os.path.join(original_image_folder, image_file)\n",
    "        image = PIL.Image.open(image_path)\n",
    "\n",
    "        # Get the original image dimensions\n",
    "        original_width, original_height = image.size\n",
    "\n",
    "        # Calculate the new width while maintaining the aspect ratio\n",
    "        new_width = int((desired_y_resolution / original_height) * original_width)\n",
    "\n",
    "        # Resize the image\n",
    "        resized_image = image.resize((new_width, desired_y_resolution))\n",
    "\n",
    "        # Save the resized image to the image_folder\n",
    "        out_p = os.path.join(image_folder, image_file)\n",
    "        resized_image.save(out_p)\n",
    "    elif image_file.endswith(\".json\"):\n",
    "        # Copy the JSON file to the image_folder\n",
    "        shutil.copy2(os.path.join(original_image_folder, image_file), image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up all API clients\n",
    "\n",
    "# Amazon Rekognition\n",
    "rekognition_client = boto3.client(\n",
    "    \"rekognition\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "# Google Vision and Cloud Storage\n",
    "credentials = service_account.Credentials.from_service_account_file(GOOGLE_KEY_PATH)\n",
    "google_client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "storage_client = storage.Client(credentials=credentials, project=GOOGLE_PROJECT_ID)\n",
    "\n",
    "# Microsoft Azure\n",
    "azure_client = ComputerVisionClient(MICROSOFT_ENDPOINT, CognitiveServicesCredentials(MICROSOFT_SUBSCRIPTION_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Rekognition API\n",
    "def detect_objects_with_rekognition(image_path: str) -> dict:\n",
    "    bucket_name = AWS_BUCKET_NAME\n",
    "    object_key = os.path.basename(image_path)\n",
    "    \n",
    "    start_upload_time = time.time()\n",
    "    s3_client.upload_file(image_path, bucket_name, object_key)\n",
    "    upload_time = (time.time() - start_upload_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = rekognition_client.detect_labels(\n",
    "            Image={\"S3Object\": {\"Bucket\": bucket_name, \"Name\": object_key}},\n",
    "            MinConfidence=REKOGNITION_CONFIDENCE_THRESHOLD\n",
    "        )\n",
    "        inference_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "        response[\"inference_time\"] = inference_time\n",
    "        response[\"upload_time\"] = upload_time\n",
    "        return response\n",
    "    except ClientError as e:\n",
    "        print(\"Error: {}\".format(e))\n",
    "        return {}\n",
    "\n",
    "def convert_rekognition_output(rekognition_output: dict, image_id: str) -> dict:\n",
    "    objects = []\n",
    "\n",
    "    for label in rekognition_output.get(\"Labels\", []):\n",
    "        for instance in label.get(\"Instances\", []):\n",
    "            bbox = instance[\"BoundingBox\"]\n",
    "            objects.append({\n",
    "                \"class_name\": label[\"Name\"],\n",
    "                \"bbox\": [bbox[\"Left\"], bbox[\"Top\"], bbox[\"Width\"], bbox[\"Height\"]],\n",
    "                \"confidence\": instance[\"Confidence\"] / 100\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"objects\": objects,\n",
    "        \"inference_time\": rekognition_output[\"inference_time\"],\n",
    "        \"upload_time\": rekognition_output[\"upload_time\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Vision\n",
    "def detect_objects_with_google_vision(image_path: str) -> dict:\n",
    "    bucket_name = GOOGLE_BUCKET_NAME  # export this later\n",
    "    blob_name = os.path.basename(image_path)\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    start_upload_time = time.time()\n",
    "    blob.upload_from_filename(image_path)\n",
    "    upload_time = (time.time() - start_upload_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "    image = vision.Image(source=vision.ImageSource(gcs_image_uri=f\"gs://{bucket_name}/{blob_name}\"))\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = google_client.object_localization(\n",
    "        image=image,\n",
    "        max_results=GOOGLE_MAX_RESULTS, \n",
    "    )\n",
    "    inference_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "    \n",
    "    return {\"response\": response, \"inference_time\": inference_time, \"upload_time\": upload_time}\n",
    "\n",
    "def convert_google_vision_output(google_vision_output: dict, image_id: str) -> dict:\n",
    "    response = google_vision_output[\"response\"]\n",
    "    objects = []\n",
    "\n",
    "    for object_ in response.localized_object_annotations:\n",
    "        vertices = object_.bounding_poly.normalized_vertices\n",
    "        objects.append({\n",
    "            \"class_name\": object_.name,\n",
    "            \"bbox\": [vertices[0].x, vertices[0].y, vertices[2].x - vertices[0].x, vertices[2].y - vertices[0].y],\n",
    "            \"confidence\": object_.score\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"objects\": objects,\n",
    "        \"inference_time\": google_vision_output[\"inference_time\"],\n",
    "        \"upload_time\": google_vision_output[\"upload_time\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft Azure\n",
    "def detect_objects_with_azure(image_path: str) -> dict:\n",
    "    container_name = AZURE_CONTAINER_NAME\n",
    "    \n",
    "    blob_service_client = BlobServiceClient.from_connection_string(AZURE_CONNECTION_STRING)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "    blob_name = os.path.basename(image_path)\n",
    "\n",
    "    start_upload_time = time.time()\n",
    "    with open(image_path, \"rb\") as data:\n",
    "        blob_client = container_client.get_blob_client(blob_name)\n",
    "        blob_client.upload_blob(data, overwrite=True)\n",
    "        container_client.set_container_access_policy(signed_identifiers={}, public_access=PublicAccess.Blob)  # Set public access level\n",
    "    upload_time = (time.time() - start_upload_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "    image_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob_name}\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    analysis = azure_client.analyze_image(\n",
    "        image_url,\n",
    "        visual_features=[VisualFeatureTypes.objects],\n",
    "        detection_model=\"detection_03\",  # Use the latest detection model\n",
    "    )\n",
    "    inference_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Delete the blob after inference\n",
    "    container_client.delete_blob(blob_name)\n",
    "\n",
    "    return {\"analysis\": analysis.as_dict(), \"inference_time\": inference_time, \"upload_time\": upload_time}\n",
    "\n",
    "\n",
    "def convert_azure_output(azure_output: dict, image_path: str) -> dict:\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    objects = []\n",
    "    for object_ in azure_output[\"analysis\"].get(\"objects\", []):\n",
    "        bbox = object_[\"rectangle\"]\n",
    "        normalized_bbox = [\n",
    "            bbox[\"x\"] / image_width,\n",
    "            bbox[\"y\"] / image_height,\n",
    "            bbox[\"w\"] / image_width,\n",
    "            bbox[\"h\"] / image_height\n",
    "        ]\n",
    "        objects.append({\n",
    "            \"class_name\": object_[\"object_property\"],\n",
    "            \"bbox\": normalized_bbox,\n",
    "            \"confidence\": object_[\"confidence\"]\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_path,\n",
    "        \"objects\": objects,\n",
    "        \"inference_time\": azure_output[\"inference_time\"],\n",
    "        \"upload_time\": azure_output[\"upload_time\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5\n",
    "def detect_objects_with_yolov5(image_path: str) -> dict:\n",
    "    image = cv2.imread(image_path)\n",
    "    image.shape[:2]\n",
    "    results = yolov5_model(image_path, conf=YOLOV8_CONFIDENCE_THRESHOLD, imgsz=image.shape[:2])\n",
    "\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"inference_time\": results[0].speed['inference']  # Retrieve inference time from YOLOv5 output\n",
    "    }\n",
    "\n",
    "def convert_yolov5_output(yolov5_output: dict, image_path: str) -> dict:\n",
    "    objects = []\n",
    "\n",
    "    # Get the image dimensions\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    for result in yolov5_output[\"results\"]:\n",
    "        for object_ in result.boxes.data.cpu().numpy():\n",
    "            xyxy = object_[:4]\n",
    "            conf = object_[4]\n",
    "            class_id = int(object_[5])\n",
    "\n",
    "            # Normalize the bounding box coordinates\n",
    "            normalized_bbox = [\n",
    "                xyxy[0] / image_width,\n",
    "                xyxy[1] / image_height,\n",
    "                (xyxy[2] - xyxy[0]) / image_width,\n",
    "                (xyxy[3] - xyxy[1]) / image_height\n",
    "            ]\n",
    "\n",
    "            objects.append({\n",
    "                \"class_name\": result.names[class_id],\n",
    "                \"bbox\": normalized_bbox,\n",
    "                \"confidence\": conf\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_path,\n",
    "        \"objects\": objects,\n",
    "        \"inference_time\": yolov5_output[\"inference_time\"],\n",
    "        \"upload_time\": 0  # Add a default upload time of 0 for local solutions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8\n",
    "def detect_objects_with_yolov8(image_path: str) -> dict:\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results = yolov8_model(image_path, conf=YOLOV8_CONFIDENCE_THRESHOLD, imgsz=image.shape[:2])\n",
    "\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"inference_time\": results[0].speed['inference']  # Retrieve inference time from YOLOv8 output\n",
    "    }\n",
    "\n",
    "def convert_yolov8_output(yolov8_output: dict, image_path: str) -> dict:\n",
    "    objects = []\n",
    "\n",
    "    # Get the image dimensions\n",
    "    image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    for result in yolov8_output[\"results\"]:\n",
    "        for object_ in result.boxes.data.cpu().numpy():\n",
    "            xyxy = object_[:4]\n",
    "            conf = object_[4]\n",
    "            class_id = int(object_[5])\n",
    "\n",
    "            # Normalize the bounding box coordinates\n",
    "            normalized_bbox = [\n",
    "                xyxy[0] / image_width,\n",
    "                xyxy[1] / image_height,\n",
    "                (xyxy[2] - xyxy[0]) / image_width,\n",
    "                (xyxy[3] - xyxy[1]) / image_height\n",
    "            ]\n",
    "\n",
    "            objects.append({\n",
    "                \"class_name\": result.names[class_id],\n",
    "                \"bbox\": normalized_bbox,\n",
    "                \"confidence\": conf\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_path,\n",
    "        \"objects\": objects,\n",
    "        \"inference_time\": yolov8_output[\"inference_time\"],\n",
    "        \"upload_time\": 0  # Add a default upload time of 0 for local solutions\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_bounding_boxes(output_dict):\n",
    "    objects = output_dict[\"objects\"]\n",
    "    objects.sort(key=lambda x: x[\"bbox\"][2] * x[\"bbox\"][3], reverse=True)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One function to run them all\n",
    "def inferenceFromAllSources(image_path: str) -> dict:\n",
    "    google_vision_out = convert_google_vision_output(detect_objects_with_google_vision(image_path), image_path)\n",
    "    azure_out = convert_azure_output(detect_objects_with_azure(image_path), image_path)\n",
    "    rekognition_out = convert_rekognition_output(detect_objects_with_rekognition(image_path), image_path)\n",
    "    yolov5_out = convert_yolov5_output(detect_objects_with_yolov5(image_path), image_path)\n",
    "    yolov8_out = convert_yolov8_output(detect_objects_with_yolov8(image_path), image_path)\n",
    "    ##yolov9_out = convert_yolov9_output(detect_objects_with_yolov9(image_path), image_path)\n",
    "\n",
    "    return {\n",
    "        \"google\": sort_bounding_boxes(google_vision_out),\n",
    "        \"azure\": sort_bounding_boxes(azure_out),\n",
    "        \"rekognition\": sort_bounding_boxes(rekognition_out),\n",
    "        \"yolov5\": sort_bounding_boxes(yolov5_out),\n",
    "        \"yolov8\": sort_bounding_boxes(yolov8_out),\n",
    "        ##\"yolov9\": sort_bounding_boxes(yolov9_out),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(data, indent_level=0):\n",
    "    indent = \"  \" * indent_level\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, dict):\n",
    "                print(f\"{indent}{key}:\")\n",
    "                print_dict(value, indent_level + 1)\n",
    "            elif isinstance(value, list) and all(isinstance(item, dict) for item in value):\n",
    "                print(f\"{indent}{key}:\")\n",
    "                for item in value:\n",
    "                    print(f\"{indent}  -\")\n",
    "                    print_dict(item, indent_level + 2)\n",
    "            else:\n",
    "                print(f\"{indent}{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{indent}{data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path, objects):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Create a dictionary to store colors for each class\n",
    "    class_colors = {}\n",
    "\n",
    "    for obj in objects:\n",
    "        class_name = obj[\"class_name\"]\n",
    "        bbox = obj[\"bbox\"]\n",
    "\n",
    "        # Generate a random color for each class if not already assigned\n",
    "        if class_name not in class_colors:\n",
    "            class_colors[class_name] = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "        color = class_colors[class_name]\n",
    "\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        height, width, _ = image.shape\n",
    "        bbox = [int(bbox[0] * width), int(bbox[1] * height), int(bbox[2] * width), int(bbox[3] * height)]\n",
    "\n",
    "        # Draw bounding box rectangle\n",
    "        cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), color, 2)\n",
    "\n",
    "        # Put class name text above the rectangle\n",
    "        cv2.putText(image, class_name, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # Convert the image to a format compatible with display()\n",
    "    _, encoded_image = cv2.imencode('.png', image)\n",
    "    display(Image(data=encoded_image.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the image file names, necessary to run\n",
    "# Load the JSON file containing the bbox data\n",
    "with open(os.path.join(image_folder, \"labels.json\"), \"r\") as file:\n",
    "    original_bbox_data = json.load(file)\n",
    "\n",
    "# Get a list of image file names\n",
    "image_files = [file for file in os.listdir(image_folder) if file.endswith(\".png\") or file.endswith(\".jpg\")]\n",
    "\n",
    "# Randomly select an image file\n",
    "selected_image = random.choice(image_files)\n",
    "image_path = os.path.join(image_folder, selected_image)\n",
    "\n",
    "# Find the corresponding bbox data for the selected image\n",
    "selected_bbox_data = next((data for data in original_bbox_data if data[\"image_id\"] == selected_image), None)\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to a format compatible with display()\n",
    "_, encoded_image = cv2.imencode('.png', image)\n",
    "display(Image(data=encoded_image.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class_names(objects):\n",
    "    # Dictionary to map alternative class names to a common class name\n",
    "    class_mapping = {\n",
    "        \"car\": [\"automobile\", \"taxi\", \"vehicle\", \"suv\", \"jeep\", \"sedan\", \"van\", \"land vehicle\", \"vehicle.car\", \"vehicle.emergency.police\"],\n",
    "        \"truck\": [\"truck\", \"lorry\", \"bus\", \"shuttle bus\", \"pickup truck\", \"vehicle.truck\", \"vehicle.bus.bendy\", \"vehicle.bus.rigid\", \"vehicle.trailer\", \"vehicle.construction\", \"vehicle.emergency.ambulance\"],\n",
    "        \"person\": [\"person\", \"pedestrian\", \"human\", \n",
    "                   \"human.pedestrian.adult\", \"human.pedestrian.child\", \"human.pedestrian.construction_worker\", \n",
    "                   \"human.pedestrian.personal_mobility\", \"human.pedestrian.police_officer\", \"human.pedestrian.stroller\", \n",
    "                   \"human.pedestrian.wheelchair\"],\n",
    "        \"biker\": [\"bicycle\", \"bike\", \"biker\", \"motorcycle\", \"motorbike\", \"vehicle.bicycle\", \"vehicle.motorcycle\"],\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "\n",
    "    converted_objects = []\n",
    "    for obj in objects:\n",
    "        class_name = obj[\"class_name\"].lower()  # Convert class name to lowercase\n",
    "        obj[\"class_name\"] = class_name  # Store the lowercase class name back in the original object\n",
    "        for common_name, alt_names in class_mapping.items():\n",
    "            if class_name == common_name or class_name in alt_names:\n",
    "                obj[\"class_name\"] = common_name\n",
    "                converted_objects.append(obj)\n",
    "                break\n",
    "        # Remove the following line to delete objects not found in the class_mapping dictionary:\n",
    "        # else: converted_objects.append(obj)\n",
    "\n",
    "    return converted_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pixel_coords(bbox, image_width, image_height):\n",
    "    x, y, w, h = bbox\n",
    "    x_min = int(x * image_width)\n",
    "    y_min = int(y * image_height)\n",
    "    x_max = int((x + w) * image_width)\n",
    "    y_max = int((y + h) * image_height)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def create_class_masks(objects, image_width, image_height):\n",
    "    class_masks = {}\n",
    "    for obj in objects:\n",
    "        class_name = obj['class_name']\n",
    "        if class_name not in class_masks:\n",
    "            class_masks[class_name] = np.zeros((image_height, image_width), dtype=int)\n",
    "        x_min, y_min, x_max, y_max = convert_to_pixel_coords(obj['bbox'], image_width, image_height)\n",
    "        class_masks[class_name][y_min:y_max, x_min:x_max] += 1\n",
    "    return class_masks\n",
    "\n",
    "def calculate_iou(inferred_objects, original_objects, image_width, image_height):\n",
    "    inferred_masks = create_class_masks(inferred_objects, image_width, image_height)\n",
    "    original_masks = create_class_masks(original_objects, image_width, image_height)\n",
    "\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "\n",
    "    # Calculate intersection for each class\n",
    "    for class_name in inferred_masks:\n",
    "        if class_name in original_masks:\n",
    "            intersection = np.minimum(inferred_masks[class_name], original_masks[class_name])\n",
    "            total_intersection += np.sum(intersection)\n",
    "\n",
    "    # Calculate union across all classes\n",
    "    all_classes = set(inferred_masks.keys()).union(set(original_masks.keys()))\n",
    "    for class_name in all_classes:\n",
    "        inferred_mask = inferred_masks.get(class_name, np.zeros((image_height, image_width), dtype=int))\n",
    "        original_mask = original_masks.get(class_name, np.zeros((image_height, image_width), dtype=int))\n",
    "        union = np.maximum(inferred_mask, original_mask)\n",
    "        total_union += np.sum(union)\n",
    "\n",
    "    iou = total_intersection / total_union if total_union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----RUN INFERENCE SEQUENTIALLY ON IMAGES\n",
    "\n",
    "# List to store the inference results for all images\n",
    "all_inference_results = []\n",
    "\n",
    "# Randomly select input_images_number of images from image_files\n",
    "selected_images = random.sample(image_files, input_images_number)\n",
    "\n",
    "# Initialize variables for failsafe and time limiting\n",
    "inference_count = 0\n",
    "last_request_time = 0\n",
    "\n",
    "# Iterate over the selected images\n",
    "for image_file in selected_images:\n",
    "    # Check if the inference limit has been reached\n",
    "    if inference_count >= inference_limit:\n",
    "        print(\"Inference limit reached. Stopping the loop.\")\n",
    "        break\n",
    "\n",
    "    # Check if enough time has passed since the last request\n",
    "    current_time = time.time()\n",
    "    elapsed_time = (current_time - last_request_time) * 1000  # Convert to milliseconds\n",
    "    if elapsed_time < request_time_limiter_ms:\n",
    "        # Wait for the remaining time to reach the request time limit\n",
    "        time.sleep((request_time_limiter_ms - elapsed_time) / 1000)\n",
    "\n",
    "    # Update the last request time\n",
    "    last_request_time = time.time()\n",
    "\n",
    "    # Construct the full image path\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "    try:\n",
    "        # Call the inferenceFromAllSources function for the current image\n",
    "        inference_result = inferenceFromAllSources(image_path)\n",
    "\n",
    "        # Append the inference result to the list\n",
    "        all_inference_results.append(inference_result)\n",
    "\n",
    "        # Increment the inference count\n",
    "        inference_count += 1\n",
    "\n",
    "        print(f\"Inference completed for {image_file}. Inference count: {inference_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during inference for {image_file}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Print the number of images processed\n",
    "print(f\"Inference completed for {len(all_inference_results)} images.\")\n",
    "#print_dict(all_inference_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_confidence_thresholds(inference_results, bbox_data, threshold_step=0.02):\n",
    "    optimal_thresholds = {}\n",
    "    image_dimensions = {}\n",
    "    bbox_data_dict = {data[\"image_id\"]: data for data in bbox_data}\n",
    "    \n",
    "    # Precompute image dimensions\n",
    "    for inference_result in inference_results:\n",
    "        for method in inference_result:\n",
    "            image_id = inference_result[method][\"image_id\"]\n",
    "            if image_id not in image_dimensions:\n",
    "                image = cv2.imread(image_id)\n",
    "                if image is not None:\n",
    "                    height, width = image.shape[:2]\n",
    "                    image_dimensions[image_id] = (width, height)\n",
    "\n",
    "    for method in inference_results[0].keys():\n",
    "        max_avg_iou = 0\n",
    "        optimal_threshold = 0\n",
    "        \n",
    "        thresholds = np.arange(0, 1 + threshold_step, threshold_step)\n",
    "        total_ious = np.zeros(thresholds.shape)\n",
    "        image_counts = np.zeros(thresholds.shape)\n",
    "\n",
    "        for inference_result in inference_results:\n",
    "            image_id = inference_result[method][\"image_id\"]\n",
    "            bbox_data_item = bbox_data_dict.get(os.path.basename(image_id))\n",
    "            if bbox_data_item:\n",
    "                width, height = image_dimensions.get(image_id, (None, None))\n",
    "                for i, threshold in enumerate(thresholds):\n",
    "                    filtered_objects = [obj for obj in inference_result[method][\"objects\"] if obj[\"confidence\"] >= threshold]\n",
    "                    image_iou = calculate_iou(filtered_objects, bbox_data_item[\"objects\"], width, height)\n",
    "                    total_ious[i] += image_iou\n",
    "                    image_counts[i] += 1\n",
    "\n",
    "        avg_ious = np.divide(total_ious, image_counts, out=np.zeros_like(total_ious), where=image_counts != 0)\n",
    "        max_avg_iou_index = np.argmax(avg_ious)\n",
    "        optimal_threshold = thresholds[max_avg_iou_index]\n",
    "\n",
    "        optimal_thresholds[method] = round(optimal_threshold, 2)\n",
    "\n",
    "    return optimal_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts class names and calculates optimal confidence thresholds for all images, also loads original bbox data\n",
    "\n",
    "# Load the JSON file containing the bbox data\n",
    "with open(os.path.join(image_folder, \"labels.json\"), \"r\") as file:\n",
    "    original_bbox_data = json.load(file)\n",
    "\n",
    "def convert_class_names_in_results(inference_results, bbox_data):\n",
    "    bbox_data_dict = {data[\"image_id\"]: data for data in bbox_data}\n",
    "\n",
    "    for inference_result in inference_results:\n",
    "        for method in inference_result:\n",
    "            inference_result[method][\"objects\"] = convert_class_names(inference_result[method][\"objects\"])\n",
    "        \n",
    "        image_file = os.path.basename(inference_result[\"yolov5\"][\"image_id\"])\n",
    "        bbox_data_item = bbox_data_dict.get(image_file)\n",
    "        \n",
    "        if bbox_data_item:\n",
    "            bbox_data_item[\"objects\"] = convert_class_names(bbox_data_item[\"objects\"])\n",
    "    \n",
    "    return inference_results, list(bbox_data_dict.values())\n",
    "\n",
    "\n",
    "# Convert class names in the inference results and original data\n",
    "all_inference_results, original_bbox_data = convert_class_names_in_results(all_inference_results, original_bbox_data)\n",
    "\n",
    "optimal_thresholds = find_optimal_confidence_thresholds(all_inference_results, original_bbox_data)\n",
    "print(optimal_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new version of all_inference_results with bboxes below the confidence threshold removed\n",
    "optimized_inference_results = []\n",
    "\n",
    "for inference_result in all_inference_results:\n",
    "    optimized_result = {}\n",
    "    for method in inference_result:\n",
    "        optimal_threshold = optimal_thresholds[method]\n",
    "        \n",
    "        # Filter objects based on the optimal confidence threshold\n",
    "        filtered_objects = [obj for obj in inference_result[method][\"objects\"] if obj[\"confidence\"] >= optimal_threshold]\n",
    "        \n",
    "        # Create a new inference result with the filtered objects\n",
    "        optimized_result[method] = {\n",
    "            \"image_id\": inference_result[method][\"image_id\"],\n",
    "            \"objects\": filtered_objects,\n",
    "            \"inference_time\": inference_result[method][\"inference_time\"],\n",
    "            \"upload_time\": inference_result[method][\"upload_time\"],\n",
    "            #\"image_iou\": inference_result[method][\"image_iou\"]\n",
    "        }\n",
    "    \n",
    "    optimized_inference_results.append(optimized_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates IoU for each image\n",
    "# Iterate over each inference result\n",
    "asd = 0\n",
    "for inference_result in optimized_inference_results:\n",
    "    asd +=1\n",
    "    # Extract the image name from the inference result\n",
    "    image_file = os.path.basename(inference_result[\"yolov5\"][\"image_id\"])\n",
    "    \n",
    "    # Find the corresponding bbox data for the image\n",
    "    bbox_data_item = next((data for data in original_bbox_data if data[\"image_id\"] == image_file), None)\n",
    "    \n",
    "    # Calculate IoU for each inference method\n",
    "    for method in inference_result:\n",
    "        if bbox_data_item is not None:\n",
    "            image = cv2.imread(inference_result[method][\"image_id\"])\n",
    "            width, height = image.shape[:2]\n",
    "            image_iou = calculate_iou(inference_result[method][\"objects\"], bbox_data_item[\"objects\"],width, height)\n",
    "            inference_result[method][\"image_iou\"] = image_iou\n",
    "        else:\n",
    "            print(f\"No corresponding bbox data found for image: {image_file}\")\n",
    "    \n",
    "    # Load and display the image with bounding boxes\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    for method in inference_result:\n",
    "        print(method)\n",
    "        print(\"Inference time:\", inference_result[method][\"inference_time\"], \"ms\")\n",
    "        print(\"IoU: \", inference_result[method][\"image_iou\"])\n",
    "        draw_bounding_boxes(image_path, inference_result[method][\"objects\"])\n",
    "    \n",
    "    # Display the original image with the original bboxes\n",
    "    print(\"Original Image:\")\n",
    "    draw_bounding_boxes(image_path, bbox_data_item[\"objects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_results(content):\n",
    "    print(content)\n",
    "    text_file.write(content + \"\\n\")\n",
    "\n",
    "# Get hardware information\n",
    "def get_cpu_info():\n",
    "    cpu_info = cpuinfo.get_cpu_info()\n",
    "    brand = cpu_info['brand_raw']\n",
    "    return brand\n",
    "\n",
    "# Get image resolution\n",
    "image_path = optimized_inference_results[0]['yolov5']['image_id']  # all images have the same resolution\n",
    "image = cv2.imread(image_path)\n",
    "height, width, _ = image.shape\n",
    "image_resolution = f\"{width}x{height}\"\n",
    "\n",
    "# Get hardware information\n",
    "cpu_info = get_cpu_info()\n",
    "ram_info = psutil.virtual_memory()\n",
    "try:\n",
    "    gpu_info = gpustat.new_query()\n",
    "except (ImportError, FileNotFoundError, Exception):\n",
    "    gpu_info = False\n",
    "\n",
    "# Calculate average inference time and image IoU for each method\n",
    "method_metrics = {}\n",
    "for inference_result in optimized_inference_results:\n",
    "    for method in inference_result:\n",
    "        if method not in method_metrics:\n",
    "            method_metrics[method] = {'inference_time': [], 'upload_time': [], 'image_iou': []}\n",
    "        method_metrics[method]['inference_time'].append(float(inference_result[method]['inference_time']))\n",
    "        method_metrics[method]['upload_time'].append(float(inference_result[method]['upload_time']))\n",
    "        method_metrics[method]['image_iou'].append(float(inference_result[method]['image_iou']))\n",
    "\n",
    "for method in method_metrics:\n",
    "    method_metrics[method]['avg_inference_time'] = np.mean(method_metrics[method]['inference_time'])\n",
    "    method_metrics[method]['avg_upload_time'] = np.mean(method_metrics[method]['upload_time'])\n",
    "    method_metrics[method]['avg_image_iou'] = np.mean(method_metrics[method]['image_iou'])\n",
    "\n",
    "# Create a folder with the current datetime as its name\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "folder_name = f\"results_{current_datetime}\"\n",
    "folder_path = os.path.join(output_path, folder_name)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Convert numpy.float32 values to regular float objects\n",
    "all_inference_results = json.loads(json.dumps(all_inference_results, default=lambda x: float(x) if isinstance(x, np.float32) else x))\n",
    "\n",
    "# Save the original all_inference_results data as a JSON file\n",
    "json_file_path = os.path.join(folder_path, \"all_inference_results.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(all_inference_results, json_file, indent=4)\n",
    "\n",
    "# Save the printed information as a text file\n",
    "text_file_path = os.path.join(folder_path, \"results.txt\")\n",
    "with open(text_file_path, \"w\") as text_file:\n",
    "    output_results(\"UPLOAD INFERENCE\")\n",
    "    output_results(f\"Number of Images Tested: {len(optimized_inference_results)}\")\n",
    "    output_results(f\"Image resolution: {image_resolution}\")\n",
    "    output_results(f\"Dataset used: {dataset_name}\")\n",
    "    output_results(f\"Dataset path: {image_folder}\")\n",
    "    output_results(\"SaaS region/server data:\")\n",
    "    output_results(f\"AWS_REGION: {AWS_REGION}\")\n",
    "    output_results(f\"GOOGLE_PROJECT_ID: {GOOGLE_PROJECT_ID}\")\n",
    "    output_results(f\"MICROSOFT_ENDPOINT: {MICROSOFT_ENDPOINT}\")\n",
    "    output_results(\"Hardware Information:\")\n",
    "    output_results(f\"CPU: {cpu_info}\")\n",
    "    output_results(f\"RAM: {ram_info.total / (1024 * 1024 * 1024):.2f} GB\")\n",
    "    if (gpu_info):\n",
    "        output_results(f\"GPU: {gpu_info.name} - {gpu_info.memory_total / 1024:.2f} GB\")\n",
    "    else:\n",
    "        output_results(\"GPU: N/A\")\n",
    "    output_results(\"Averaged Results:\")\n",
    "    for method, metrics in method_metrics.items():\n",
    "        output_results(f\"{method}:\")\n",
    "        output_results(f\" Average Inference Time: {metrics['avg_inference_time']:.2f} ms\")\n",
    "        output_results(f\" Average Upload Time: {metrics['avg_upload_time']:.2f} ms\")\n",
    "        output_results(f\" Average Image IoU: {metrics['avg_image_iou']:.4f}\")\n",
    "        output_results(f\" Optimal confidence threshold used: {optimal_thresholds[method]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "methods = list(method_metrics.keys())\n",
    "avg_inference_times = [method_metrics[method]['avg_inference_time'] for method in methods]\n",
    "avg_upload_times = [method_metrics[method]['avg_upload_time'] for method in methods]\n",
    "avg_image_ious = [method_metrics[method]['avg_image_iou'] for method in methods]\n",
    "\n",
    "# Create and save the average inference time and upload time plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(methods))\n",
    "plt.bar(x, avg_inference_times, bar_width, label='Inference Time')\n",
    "plt.bar(x, avg_upload_times, bar_width, bottom=avg_inference_times, label='Upload Time')\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Average Inference Time and Upload Time by Method')\n",
    "plt.xticks(x, methods, rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"avg_inference_upload_time.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Create and save the average image IoU plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(methods, avg_image_ious)\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Average Image IoU')\n",
    "plt.title('Average Image IoU by Method')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"avg_image_iou.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Scatter charts showing how the average changes for both inference and accuracy over each inference call\n",
    "inference_times = {method: [] for method in methods}\n",
    "image_ious = {method: [] for method in methods}\n",
    "\n",
    "for inference_result in optimized_inference_results:\n",
    "    for method in methods:\n",
    "        inference_times[method].append(float(inference_result[method]['inference_time']))\n",
    "        image_ious[method].append(float(inference_result[method]['image_iou']))\n",
    "\n",
    "# Combined line and scatter plots for inference time\n",
    "plt.figure(figsize=(12, 6))\n",
    "for method in methods:\n",
    "    plt.plot(range(1, len(inference_times[method]) + 1), inference_times[method], label=method)\n",
    "    plt.scatter(range(1, len(inference_times[method]) + 1), inference_times[method])\n",
    "plt.xlabel('Inference Call')\n",
    "plt.ylabel('Inference Time (ms)')\n",
    "plt.title('Inference Time')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"inference_time.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Combined line and scatter plots for image IoU\n",
    "plt.figure(figsize=(12, 6))\n",
    "for method in methods:\n",
    "    plt.plot(range(1, len(image_ious[method]) + 1), image_ious[method], label=method)\n",
    "    plt.scatter(range(1, len(image_ious[method]) + 1), image_ious[method])\n",
    "plt.xlabel('Inference Call')\n",
    "plt.ylabel('Image IoU')\n",
    "plt.title('Image IoU')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"image_iou.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Histograms to visualize variance of confidence values, inference times, and IoU throughout each inference of image\n",
    "confidence_values = {method: [] for method in methods}\n",
    "inference_times_hist = {method: [] for method in methods}\n",
    "image_ious_hist = {method: [] for method in methods}\n",
    "\n",
    "for inference_result in optimized_inference_results:\n",
    "    for method in methods:\n",
    "        for obj in inference_result[method]['objects']:\n",
    "            confidence_values[method].append(obj['confidence'])\n",
    "        inference_times_hist[method].append(float(inference_result[method]['inference_time']))\n",
    "        image_ious_hist[method].append(float(inference_result[method]['image_iou']))\n",
    "\n",
    "# Confidence Value Distribution\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "for i, method in enumerate(methods):\n",
    "    axs[i].hist(confidence_values[method], bins=np.linspace(0, 1, 21), density=True)\n",
    "    axs[i].set_xlabel('Confidence Value')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].set_title(f'Confidence Value Distribution - {method}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"confidence_value_distribution.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Inference Time Distribution\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "max_inference_time = max(max(times) for times in inference_times_hist.values())\n",
    "bins = np.linspace(0, max_inference_time, 21)\n",
    "for i, method in enumerate(methods):\n",
    "    axs[i].hist(inference_times_hist[method], bins=bins, density=True)\n",
    "    axs[i].set_xlabel('Inference Time (ms)')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].set_title(f'Inference Time Distribution - {method}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"inference_time_distribution.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Image IoU Distribution\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "for i, method in enumerate(methods):\n",
    "    axs[i].hist(image_ious_hist[method], bins=np.linspace(0, 1, 21), density=True)\n",
    "    axs[i].set_xlabel('Image IoU')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].set_title(f'Image IoU Distribution - {method}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"image_iou_distribution.png\"))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_test_path_image = \"G:\\\\My Drive\\\\Thesis2024\\\\data\\\\train\\\\1478897977253835405_jpg.rf.k1YHtF480ieDxDfcboNr.jpg\"\n",
    "#test_aio = inferenceFromAllSources(single_test_path_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in test_aio:\n",
    "        print(method)\n",
    "        print(\"Inference time:\", test_aio[method][\"inference_time\"], \"ms\")\n",
    "        #print(\"IoU: \", inference_result[method][\"image_iou\"])\n",
    "        draw_bounding_boxes(single_test_path_image, test_aio[method][\"objects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved file\n",
    "# Specify the path to the JSON file containing the saved inference results\n",
    "json_file_path = os.path.join(folder_path, \"all_inference_results.json\")\n",
    "\n",
    "# Read the JSON file and load the data into the all_inference_results variable\n",
    "with open(json_file_path, \"r\") as json_file:\n",
    "    all_inference_results = json.load(json_file)\n",
    "\n",
    "# Print the loaded data to verify it has been read correctly\n",
    "print(\"Loaded data from JSON file:\")\n",
    "print(all_inference_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
