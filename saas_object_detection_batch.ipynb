{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary python packages\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from google.cloud import vision, storage\n",
    "from google.oauth2 import service_account\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient, BlobClient, StandardBlobTier, PublicAccess\n",
    "import torch\n",
    "import io, json\n",
    "import cv2\n",
    "import os, shutil\n",
    "import random\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import psutil, gpustat, cpuinfo\n",
    "import PIL\n",
    "\n",
    "yolov5_model = YOLO('yolov5s.pt')\n",
    "yolov8_model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing the images and bbox data\n",
    "dataset_name = \"Roboflow, Self Driving Car Image Dataset\"\n",
    "original_image_folder = \"C:\\\\Users\\\\feren\\\\Downloads\\\\Self Driving Car.v2-fixed-large.coco\\\\OUTPUT\\\\train\"\n",
    "\n",
    "#dataset_name = \"NuImages\"\n",
    "#original_image_folder = \"C:\\\\Users\\\\feren\\\\Downloads\\\\nuimages_output\\\\train\"\n",
    "\n",
    "image_folder = \"temp_images\"\n",
    "output_path = \"G:\\\\My Drive\\\\Thesis2024\\\\output\"\n",
    "\n",
    "# Specify the desired Y-axis resolution\n",
    "desired_y_resolution = 1200 #480 = VGA, 1200 = max\n",
    "\n",
    "# Batch size for processing images\n",
    "batch_size = 16\n",
    "inference_limit = 200\n",
    "request_time_limiter_ms = 0\n",
    "input_images_number = 200\n",
    "\n",
    "GOOGLE_MAX_RESULTS = 100 # no threshold setting\n",
    "REKOGNITION_CONFIDENCE_THRESHOLD = 0 # in percentage\n",
    "YOLOV5_CONFIDENCE_THRESHOLD = 0.0\n",
    "YOLOV8_CONFIDENCE_THRESHOLD = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change image resolution\n",
    "\n",
    "# Delete the image_folder and its contents if it exists\n",
    "if os.path.exists(image_folder):\n",
    "    shutil.rmtree(image_folder)\n",
    "# Create the image_folder directory if it doesn't exist\n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "# Iterate over the images in the original folder\n",
    "for image_file in os.listdir(original_image_folder):\n",
    "    # Check if the file is an image\n",
    "    if image_file.endswith(\".png\") or image_file.endswith(\".jpg\"):\n",
    "        # Open the image using PIL\n",
    "        image_path = os.path.join(original_image_folder, image_file)\n",
    "        image = PIL.Image.open(image_path)\n",
    "\n",
    "        # Get the original image dimensions\n",
    "        original_width, original_height = image.size\n",
    "\n",
    "        # Calculate the new width while maintaining the aspect ratio\n",
    "        new_width = int((desired_y_resolution / original_height) * original_width)\n",
    "\n",
    "        # Resize the image\n",
    "        resized_image = image.resize((new_width, desired_y_resolution))\n",
    "\n",
    "        # Save the resized image to the image_folder\n",
    "        out_p = os.path.join(image_folder, image_file)\n",
    "        resized_image.save(out_p)\n",
    "    elif image_file.endswith(\".json\"):\n",
    "        # Copy the JSON file to the image_folder\n",
    "        shutil.copy2(os.path.join(original_image_folder, image_file), image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up all API clients\n",
    "\n",
    "# Amazon Rekognition\n",
    "rekognition_client = boto3.client(\n",
    "    \"rekognition\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "# Google Vision and Cloud Storage\n",
    "credentials = service_account.Credentials.from_service_account_file(GOOGLE_KEY_PATH)\n",
    "google_client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "storage_client = storage.Client(credentials=credentials, project=GOOGLE_PROJECT_ID)\n",
    "\n",
    "# Microsoft Azure\n",
    "azure_client = ComputerVisionClient(MICROSOFT_ENDPOINT, CognitiveServicesCredentials(MICROSOFT_SUBSCRIPTION_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Rekognition API\n",
    "def detect_objects_with_rekognition(image_paths: list) -> list:\n",
    "    bucket_name = \"fankfurteucentralrekognition\"  # export this later\n",
    "    responses = []\n",
    "\n",
    "    # Upload all images to S3\n",
    "    for image_path in image_paths:\n",
    "        object_key = os.path.basename(image_path)\n",
    "        start_upload_time = time.time()\n",
    "        s3_client.upload_file(image_path, bucket_name, object_key)\n",
    "        upload_time = (time.time() - start_upload_time) * 1000  # Convert to milliseconds\n",
    "        responses.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"object_key\": object_key,\n",
    "            \"upload_time\": upload_time\n",
    "        })\n",
    "\n",
    "    # Perform inference on all images\n",
    "    for response in responses:\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            rekognition_response = rekognition_client.detect_labels(\n",
    "                Image={\"S3Object\": {\"Bucket\": bucket_name, \"Name\": response[\"object_key\"]}},\n",
    "                MinConfidence=REKOGNITION_CONFIDENCE_THRESHOLD\n",
    "            )\n",
    "            inference_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "            rekognition_response[\"inference_time\"] = inference_time\n",
    "            rekognition_response[\"upload_time\"] = response[\"upload_time\"]\n",
    "            response[\"rekognition_response\"] = rekognition_response\n",
    "        except ClientError as e:\n",
    "            print(\"Error: {}\".format(e))\n",
    "            response[\"rekognition_response\"] = {}\n",
    "\n",
    "        # Clean up the S3 object\n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=response[\"object_key\"])\n",
    "\n",
    "    return responses\n",
    "\n",
    "def convert_rekognition_output(rekognition_outputs: list) -> list:\n",
    "    converted_outputs = []\n",
    "\n",
    "    for rekognition_output in rekognition_outputs:\n",
    "        if \"rekognition_response\" not in rekognition_output:\n",
    "            print(f\"Missing rekognition_response in output for image {rekognition_output.get('image_path', 'unknown')}\")\n",
    "            continue\n",
    "        objects = []\n",
    "        for label in rekognition_output[\"rekognition_response\"].get(\"Labels\", []):\n",
    "            for instance in label.get(\"Instances\", []):\n",
    "                bbox = instance[\"BoundingBox\"]\n",
    "                objects.append({\n",
    "                    \"class_name\": label[\"Name\"],\n",
    "                    \"bbox\": [bbox[\"Left\"], bbox[\"Top\"], bbox[\"Width\"], bbox[\"Height\"]],\n",
    "                    \"confidence\": instance[\"Confidence\"] / 100\n",
    "                })\n",
    "\n",
    "        converted_outputs.append({\n",
    "            \"image_id\": rekognition_output[\"image_path\"],\n",
    "            \"objects\": objects,\n",
    "            \"inference_time\": rekognition_output[\"rekognition_response\"][\"inference_time\"],\n",
    "            \"upload_time\": rekognition_output[\"rekognition_response\"][\"upload_time\"]\n",
    "        })\n",
    "\n",
    "    return converted_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Vision\n",
    "def detect_objects_with_google_vision(image_paths: list) -> list:\n",
    "    bucket_name = \"objectdetectionbucket_szakdoga\"\n",
    "    responses = []\n",
    "\n",
    "    # Batch upload all images to Google Cloud Storage\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = []\n",
    "    start_upload_time = time.time()\n",
    "    for image_path in image_paths:\n",
    "        blob_name = os.path.basename(image_path)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob.upload_from_filename(image_path)\n",
    "        blobs.append(blob)\n",
    "    total_upload_time = (time.time() - start_upload_time) * 1000  # Convert to milliseconds\n",
    "    average_upload_time = total_upload_time / len(image_paths)  # Average upload time per image\n",
    "\n",
    "    for blob in blobs:\n",
    "        responses.append({\n",
    "            \"image_path\": blob.name,\n",
    "            \"blob_name\": blob.name,\n",
    "            \"upload_time\": average_upload_time\n",
    "        })\n",
    "\n",
    "    # Perform batch inference on all images\n",
    "    image_requests = [\n",
    "        vision.AnnotateImageRequest(\n",
    "            image=vision.Image(source=vision.ImageSource(gcs_image_uri=f\"gs://{bucket_name}/{blob.name}\")),\n",
    "            features=[vision.Feature(type=vision.Feature.Type.OBJECT_LOCALIZATION, max_results=GOOGLE_MAX_RESULTS)]\n",
    "        )\n",
    "        for blob in blobs\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    vision_responses = google_client.batch_annotate_images(requests=image_requests)\n",
    "    total_inference_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "    average_inference_time = total_inference_time / len(image_paths)  # Average inference time per image\n",
    "\n",
    "    for response, vision_response in zip(responses, vision_responses.responses):\n",
    "        response[\"vision_response\"] = {\"response\": vision_response, \"inference_time\": average_inference_time}\n",
    "\n",
    "        # Clean up the blob\n",
    "        blob = bucket.blob(response[\"blob_name\"])\n",
    "        blob.delete()\n",
    "\n",
    "    return responses\n",
    "\n",
    "def convert_google_vision_output(google_vision_outputs: list) -> list:\n",
    "    converted_outputs = []\n",
    "\n",
    "    for google_vision_output in google_vision_outputs:\n",
    "        if \"vision_response\" not in google_vision_output:\n",
    "            print(f\"Missing vision_response in output for image {google_vision_output.get('image_path', 'unknown')}\")\n",
    "            continue\n",
    "        response = google_vision_output[\"vision_response\"][\"response\"]\n",
    "        objects = []\n",
    "\n",
    "        for object_ in response.localized_object_annotations:\n",
    "            vertices = object_.bounding_poly.normalized_vertices\n",
    "            objects.append({\n",
    "                \"class_name\": object_.name,\n",
    "                \"bbox\": [vertices[0].x, vertices[0].y, vertices[2].x - vertices[0].x, vertices[2].y - vertices[0].y],\n",
    "                \"confidence\": object_.score\n",
    "            })\n",
    "\n",
    "        converted_outputs.append({\n",
    "            \"image_id\": google_vision_output[\"image_path\"],\n",
    "            \"objects\": objects,\n",
    "            \"inference_time\": google_vision_output[\"vision_response\"][\"inference_time\"],\n",
    "            \"upload_time\": google_vision_output[\"upload_time\"]\n",
    "        })\n",
    "\n",
    "    return converted_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft Azure\n",
    "def detect_objects_with_azure(image_paths: list) -> list:\n",
    "    container_name = \"container1\"  # export this later\n",
    "    responses = []\n",
    "\n",
    "    # Upload all images to Azure Blob Storage\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(\"CENSORED\")\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    for image_path in image_paths:\n",
    "        blob_name = os.path.basename(image_path)\n",
    "        start_upload_time = time.time()\n",
    "        with open(image_path, \"rb\") as data:\n",
    "            blob_client = container_client.get_blob_client(blob_name)\n",
    "            blob_client.upload_blob(data, overwrite=True)\n",
    "        upload_time = (time.time() - start_upload_time) * 1000  # Convert to milliseconds\n",
    "        responses.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"blob_name\": blob_name,\n",
    "            \"upload_time\": upload_time\n",
    "        })\n",
    "\n",
    "    # Perform inference on all images\n",
    "    for response in responses:\n",
    "        image_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{response[blob_name]}\"\n",
    "        start_time = time.time()\n",
    "        analysis = azure_client.analyze_image(\n",
    "            image_url,\n",
    "            visual_features=[VisualFeatureTypes.objects],\n",
    "            detection_model=\"detection_03\",\n",
    "        )\n",
    "        inference_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "        response[\"azure_response\"] = {\"analysis\": analysis.as_dict(), \"inference_time\": inference_time}\n",
    "\n",
    "        # Clean up the blob\n",
    "        container_client.delete_blob(response[blob_name])\n",
    "\n",
    "    return responses\n",
    "\n",
    "def convert_azure_output(azure_outputs: list) -> list:\n",
    "    converted_outputs = []\n",
    "\n",
    "    for azure_output in azure_outputs:\n",
    "        if \"azure_response\" not in azure_output:\n",
    "            print(f\"Missing azure_response in output for image {azure_output.get('image_path', 'unknown')}\")\n",
    "            continue\n",
    "        image = cv2.imread(azure_output[\"image_path\"])\n",
    "        if image is None:\n",
    "            print(f\"Could not read image for {azure_output.get('image_path', 'unknown')}\")\n",
    "            continue\n",
    "\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "        objects = []\n",
    "        for object_ in azure_output[\"azure_response\"][\"analysis\"].get(\"objects\", []):\n",
    "            bbox = object_[\"rectangle\"]\n",
    "            normalized_bbox = [\n",
    "                bbox[\"x\"] / image_width,\n",
    "                bbox[\"y\"] / image_height,\n",
    "                bbox[\"w\"] / image_width,\n",
    "                bbox[\"h\"] / image_height\n",
    "            ]\n",
    "            objects.append({\n",
    "                \"class_name\": object_[\"object_property\"],\n",
    "                \"bbox\": normalized_bbox,\n",
    "                \"confidence\": object_[\"confidence\"]\n",
    "            })\n",
    "\n",
    "        converted_outputs.append({\n",
    "            \"image_id\": azure_output[\"image_path\"],\n",
    "            \"objects\": objects,\n",
    "            \"inference_time\": azure_output[\"azure_response\"][\"inference_time\"],\n",
    "            \"upload_time\": azure_output[\"upload_time\"]\n",
    "        })\n",
    "\n",
    "    return converted_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5\n",
    "def detect_objects_with_yolov5(image_paths: list) -> list:\n",
    "    image = cv2.imread(image_paths[0])\n",
    "    \n",
    "    results = yolov5_model(image_paths, conf=YOLOV5_CONFIDENCE_THRESHOLD, imgsz=image.shape[:2])\n",
    "    outputs = []\n",
    "    for idx, result in enumerate(results):\n",
    "        outputs.append({\n",
    "            \"results\": result,\n",
    "            \"inference_time\": result.speed['inference']  # Retrieve inference time from YOLOv5 output\n",
    "        })\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def convert_yolov5_output(yolov5_outputs: list) -> list:\n",
    "    converted_outputs = []\n",
    "\n",
    "    for yolov5_output in yolov5_outputs:\n",
    "        try:\n",
    "            if \"results\" not in yolov5_output:\n",
    "                print(f\"Missing results in output for image {yolov5_output.get('image_path', 'unknown')}\")\n",
    "                continue\n",
    "\n",
    "            # Extract image path from the results object\n",
    "            results = yolov5_output[\"results\"]\n",
    "            print(results)\n",
    "            image_path = results.path if hasattr(results, 'path') else \"unknown\"\n",
    "            if image_path == \"unknown\":\n",
    "                print(f\"Image path not found in YOLOv5 output: {yolov5_output}\")\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Could not read image for {image_path}\")\n",
    "                continue\n",
    "\n",
    "            image_height, image_width, _ = image.shape\n",
    "            objects = []\n",
    "\n",
    "            for object_ in results.boxes.data.cpu().numpy():\n",
    "                xyxy = object_[:4]\n",
    "                conf = object_[4]\n",
    "                class_id = int(object_[5])\n",
    "\n",
    "                normalized_bbox = [\n",
    "                    xyxy[0] / image_width,\n",
    "                    xyxy[1] / image_height,\n",
    "                    (xyxy[2] - xyxy[0]) / image_width,\n",
    "                    (xyxy[3] - xyxy[1]) / image_height\n",
    "                ]\n",
    "\n",
    "                objects.append({\n",
    "                    \"class_name\": results.names[class_id],\n",
    "                    \"bbox\": normalized_bbox,\n",
    "                    \"confidence\": conf\n",
    "                })\n",
    "\n",
    "            converted_outputs.append({\n",
    "                \"image_id\": image_path,\n",
    "                \"objects\": objects,\n",
    "                \"inference_time\": yolov5_output.get(\"inference_time\", 0),\n",
    "                \"upload_time\": 0  # Add a default upload time of 0 for local solutions\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing YOLOv5 output for image: {image_path} - {str(e)}\")\n",
    "\n",
    "    return converted_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8\n",
    "def detect_objects_with_yolov8(image_paths: list) -> list:\n",
    "    image = cv2.imread(image_paths[0])\n",
    "    \n",
    "    results = yolov8_model(image_paths, conf=YOLOV8_CONFIDENCE_THRESHOLD, imgsz=image.shape[:2])\n",
    "    print(results)\n",
    "    outputs = []\n",
    "    for idx, result in enumerate(results):\n",
    "        outputs.append({\n",
    "            \"results\": result,\n",
    "            \"inference_time\": result.speed['inference']  # Retrieve inference time from YOLOv8 output\n",
    "        })\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def convert_yolov8_output(yolov8_outputs: list) -> list:\n",
    "    converted_outputs = []\n",
    "\n",
    "    for yolov8_output in yolov8_outputs:\n",
    "        try:\n",
    "            if \"results\" not in yolov8_output:\n",
    "                print(f\"Missing results in output for image {yolov8_output.get('image_path', 'unknown')}\")\n",
    "                continue\n",
    "\n",
    "            # Extract image path from the results object\n",
    "            results = yolov8_output[\"results\"]\n",
    "            image_path = results.path if hasattr(results, 'path') else \"unknown\"\n",
    "            if image_path == \"unknown\":\n",
    "                print(f\"Image path not found in YOLOv8 output: {yolov8_output}\")\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Could not read image for {image_path}\")\n",
    "                continue\n",
    "\n",
    "            image_height, image_width, _ = image.shape\n",
    "            objects = []\n",
    "\n",
    "            for object_ in results.boxes.data.cpu().numpy():\n",
    "                xyxy = object_[:4]\n",
    "                conf = object_[4]\n",
    "                class_id = int(object_[5])\n",
    "\n",
    "                normalized_bbox = [\n",
    "                    xyxy[0] / image_width,\n",
    "                    xyxy[1] / image_height,\n",
    "                    (xyxy[2] - xyxy[0]) / image_width,\n",
    "                    (xyxy[3] - xyxy[1]) / image_height\n",
    "                ]\n",
    "\n",
    "                objects.append({\n",
    "                    \"class_name\": results.names[class_id],\n",
    "                    \"bbox\": normalized_bbox,\n",
    "                    \"confidence\": conf\n",
    "                })\n",
    "\n",
    "            converted_outputs.append({\n",
    "                \"image_id\": image_path,\n",
    "                \"objects\": objects,\n",
    "                \"inference_time\": yolov8_output.get(\"inference_time\", 0),\n",
    "                \"upload_time\": 0  # Add a default upload time of 0 for local solutions\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing YOLOv8 output for image: {image_path} - {str(e)}\")\n",
    "\n",
    "    return converted_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_bounding_boxes(output_dict):\n",
    "    objects = output_dict[\"objects\"]\n",
    "    objects.sort(key=lambda x: x[\"bbox\"][2] * x[\"bbox\"][3], reverse=True)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferenceFromAllSources(image_paths: list) -> list:\n",
    "    try:\n",
    "        print(\"Calling detect on Google...\")\n",
    "        google_vision_responses = detect_objects_with_google_vision(image_paths)\n",
    "        print(\"Google responses received\")\n",
    "        '''\n",
    "        print(\"Calling detect on Azure...\")\n",
    "        #azure_responses = detect_objects_with_azure(image_paths)\n",
    "        print(\"Azure responses received\")\n",
    "\n",
    "        print(\"Calling detect on AWS...\")\n",
    "        #rekognition_responses = detect_objects_with_rekognition(image_paths)\n",
    "        print(\"AWS responses received\")\n",
    "\n",
    "        print(\"Calling detect on YOLOv5...\")\n",
    "        yolov5_responses = detect_objects_with_yolov5(image_paths)\n",
    "        print(\"YOLOv5 responses received\")\n",
    "\n",
    "        print(\"Calling detect on YOLOv8...\")\n",
    "        yolov8_responses = detect_objects_with_yolov8(image_paths)\n",
    "        print(\"YOLOv8 responses received\")\n",
    "        '''\n",
    "\n",
    "        print(\"Calling conversion on Google...\")\n",
    "        google_vision_outputs = convert_google_vision_output(google_vision_responses)\n",
    "        print(\"Google conversion completed\")\n",
    "        '''\n",
    "\n",
    "        print(\"Calling conversion on Azure...\")\n",
    "        #azure_outputs = convert_azure_output(azure_responses)\n",
    "        print(\"Azure conversion completed\")\n",
    "\n",
    "        print(\"Calling conversion on AWS...\")\n",
    "        #rekognition_outputs = convert_rekognition_output(rekognition_responses)\n",
    "        print(\"AWS conversion completed\")\n",
    "\n",
    "        print(\"Calling conversion on YOLOv5...\")\n",
    "        yolov5_outputs = convert_yolov5_output(yolov5_responses)\n",
    "        print(\"YOLOv5 conversion completed\")\n",
    "\n",
    "        print(\"Calling conversion on YOLOv8...\")\n",
    "        yolov8_outputs = convert_yolov8_output(yolov8_responses)\n",
    "        print(\"YOLOv8 conversion completed\")\n",
    "\n",
    "        '''\n",
    "        combined_responses = []\n",
    "        for idx in range(len(image_paths)):\n",
    "            try:\n",
    "                print(f\"Combining results for image {image_paths[idx]}\")\n",
    "                combined_responses.append({\n",
    "                    \"google\": sort_bounding_boxes(google_vision_outputs[idx]),\n",
    "                    #\"azure\": sort_bounding_boxes(azure_outputs[idx]),\n",
    "                    #\"rekognition\": sort_bounding_boxes(rekognition_outputs[idx]),\n",
    "                    #\"yolov5\": sort_bounding_boxes(yolov5_outputs[idx]),\n",
    "                    #\"yolov8\": sort_bounding_boxes(yolov8_outputs[idx])\n",
    "                })\n",
    "            except KeyError as e:\n",
    "                print(f\"Missing key in response for image {image_paths[idx]}: {e}\")\n",
    "                continue\n",
    "\n",
    "        return combined_responses\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inferenceFromAllSources: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(data, indent_level=0):\n",
    "    indent = \"  \" * indent_level\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, dict):\n",
    "                print(f\"{indent}{key}:\")\n",
    "                print_dict(value, indent_level + 1)\n",
    "            elif isinstance(value, list) and all(isinstance(item, dict) for item in value):\n",
    "                print(f\"{indent}{key}:\")\n",
    "                for item in value:\n",
    "                    print(f\"{indent}  -\")\n",
    "                    print_dict(item, indent_level + 2)\n",
    "            else:\n",
    "                print(f\"{indent}{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{indent}{data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path, objects):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Create a dictionary to store colors for each class\n",
    "    class_colors = {}\n",
    "\n",
    "    for obj in objects:\n",
    "        class_name = obj[\"class_name\"]\n",
    "        bbox = obj[\"bbox\"]\n",
    "\n",
    "        # Generate a random color for each class if not already assigned\n",
    "        if class_name not in class_colors:\n",
    "            class_colors[class_name] = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "        color = class_colors[class_name]\n",
    "\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        height, width, _ = image.shape\n",
    "        bbox = [int(bbox[0] * width), int(bbox[1] * height), int(bbox[2] * width), int(bbox[3] * height)]\n",
    "\n",
    "        # Draw bounding box rectangle\n",
    "        cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), color, 2)\n",
    "\n",
    "        # Put class name text above the rectangle\n",
    "        cv2.putText(image, class_name, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # Convert the image to a format compatible with display()\n",
    "    _, encoded_image = cv2.imencode('.png', image)\n",
    "    display(Image(data=encoded_image.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the image file names, necessary to run\n",
    "# Load the JSON file containing the bbox data\n",
    "with open(os.path.join(image_folder, \"labels.json\"), \"r\") as file:\n",
    "    original_bbox_data = json.load(file)\n",
    "\n",
    "# Get a list of image file names\n",
    "image_files = [file for file in os.listdir(image_folder) if file.endswith(\".png\") or file.endswith(\".jpg\")]\n",
    "\n",
    "# Randomly select an image file\n",
    "selected_image = random.choice(image_files)\n",
    "image_path = os.path.join(image_folder, selected_image)\n",
    "\n",
    "# Find the corresponding bbox data for the selected image\n",
    "selected_bbox_data = next((data for data in original_bbox_data if data[\"image_id\"] == selected_image), None)\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to a format compatible with display()\n",
    "_, encoded_image = cv2.imencode('.png', image)\n",
    "display(Image(data=encoded_image.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class_names(objects):\n",
    "    # Dictionary to map alternative class names to a common class name\n",
    "    class_mapping = {\n",
    "        \"car\": [\"automobile\", \"taxi\", \"vehicle\", \"suv\", \"jeep\", \"sedan\", \"van\", \"land vehicle\", \"vehicle.car\", \"vehicle.emergency.police\"],\n",
    "        \"truck\": [\"truck\", \"lorry\", \"bus\", \"shuttle bus\", \"pickup truck\", \"vehicle.truck\", \"vehicle.bus.bendy\", \"vehicle.bus.rigid\", \"vehicle.trailer\", \"vehicle.construction\", \"vehicle.emergency.ambulance\"],\n",
    "        \"person\": [\"person\", \"pedestrian\", \"human\", \n",
    "                   \"human.pedestrian.adult\", \"human.pedestrian.child\", \"human.pedestrian.construction_worker\", \n",
    "                   \"human.pedestrian.personal_mobility\", \"human.pedestrian.police_officer\", \"human.pedestrian.stroller\", \n",
    "                   \"human.pedestrian.wheelchair\"],\n",
    "        \"biker\": [\"bicycle\", \"bike\", \"biker\", \"motorcycle\", \"motorbike\", \"vehicle.bicycle\", \"vehicle.motorcycle\"],\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "\n",
    "    converted_objects = []\n",
    "    for obj in objects:\n",
    "        class_name = obj[\"class_name\"].lower()  # Convert class name to lowercase\n",
    "        obj[\"class_name\"] = class_name  # Store the lowercase class name back in the original object\n",
    "        for common_name, alt_names in class_mapping.items():\n",
    "            if class_name == common_name or class_name in alt_names:\n",
    "                obj[\"class_name\"] = common_name\n",
    "                converted_objects.append(obj)\n",
    "                break\n",
    "        # Remove the following line to delete objects not found in the class_mapping dictionary:\n",
    "        # else: converted_objects.append(obj)\n",
    "\n",
    "    return converted_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----RUN INFERENCE SEQUENTIALLY ON IMAGES\n",
    "\n",
    "# List to store the inference results for all images\n",
    "all_inference_results = []\n",
    "\n",
    "# Randomly select input_images_number of images from image_files\n",
    "selected_images = random.sample(image_files, input_images_number)\n",
    "selected_image_paths = [os.path.join(image_folder, image_file) for image_file in selected_images]\n",
    "\n",
    "# Initialize variables for failsafe and time limiting\n",
    "inference_count = 0\n",
    "last_request_time = 0\n",
    "\n",
    "# Process images in batches\n",
    "for i in range(0, len(selected_image_paths), batch_size):\n",
    "    batch_paths = selected_image_paths[i:i + batch_size]\n",
    "    \n",
    "    # Check if the inference limit has been reached\n",
    "    if inference_count >= inference_limit:\n",
    "        print(\"Inference limit reached. Stopping the loop.\")\n",
    "        break\n",
    "\n",
    "    # Check if enough time has passed since the last request\n",
    "    current_time = time.time()\n",
    "    elapsed_time = (current_time - last_request_time) * 1000  # Convert to milliseconds\n",
    "    if elapsed_time < request_time_limiter_ms:\n",
    "        # Wait for the remaining time to reach the request time limit\n",
    "        time.sleep((request_time_limiter_ms - elapsed_time) / 1000)\n",
    "\n",
    "    # Update the last request time\n",
    "    last_request_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Call the inferenceFromAllSources function for the current batch\n",
    "        batch_inference_result = inferenceFromAllSources(batch_paths)\n",
    "        \n",
    "        # Append the inference result to the list\n",
    "        all_inference_results.extend(batch_inference_result)\n",
    "\n",
    "        # Increment the inference count by the batch size\n",
    "        inference_count += len(batch_paths)\n",
    "\n",
    "        print(f\"Inference completed for batch starting with {batch_paths[0]}. Total inference count: {inference_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during inference for batch starting with {batch_paths[0]}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Print the number of images processed\n",
    "print(f\"Inference completed for {len(all_inference_results)} images.\")\n",
    "print_dict(all_inference_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def calculate_iou(inferred_objects, original_objects):\n",
    "    def merge_boxes(boxes):\n",
    "        polygons = [box(b[0], b[1], b[0] + b[2], b[1] + b[3]) for b in boxes]\n",
    "        merged = unary_union(polygons)\n",
    "        if merged.geom_type == 'Polygon':\n",
    "            merged = [merged]\n",
    "        return merged\n",
    "\n",
    "    def calculate_area(polygons):\n",
    "        return sum(p.area for p in polygons)\n",
    "    \n",
    "    inferred_areas = {}\n",
    "    original_areas = {}\n",
    "    \n",
    "    total_inferred_area = 0\n",
    "    total_original_area = 0\n",
    "\n",
    "    for inf_obj in inferred_objects:\n",
    "        class_name = inf_obj['class_name']\n",
    "        if class_name not in inferred_areas:\n",
    "            inferred_areas[class_name] = []\n",
    "        inferred_areas[class_name].append(inf_obj['bbox'])\n",
    "        total_inferred_area += inf_obj['bbox'][2] * inf_obj['bbox'][3]\n",
    "\n",
    "    for org_obj in original_objects:\n",
    "        class_name = org_obj['class_name']\n",
    "        if class_name not in original_areas:\n",
    "            original_areas[class_name] = []\n",
    "        original_areas[class_name].append(org_obj['bbox'])\n",
    "        total_original_area += org_obj['bbox'][2] * org_obj['bbox'][3]\n",
    "\n",
    "    merged_inferred_areas = {class_name: merge_boxes(boxes) for class_name, boxes in inferred_areas.items()}\n",
    "    merged_original_areas = {class_name: merge_boxes(boxes) for class_name, boxes in original_areas.items()}\n",
    "\n",
    "    total_intersection_area = 0\n",
    "\n",
    "    for class_name in set(merged_inferred_areas.keys()).union(set(merged_original_areas.keys())):\n",
    "        inferred_polygons = merged_inferred_areas.get(class_name, [])\n",
    "        original_polygons = merged_original_areas.get(class_name, [])\n",
    "        intersection_polygons = [p1.intersection(p2) for p1 in inferred_polygons for p2 in original_polygons]\n",
    "        intersection_area = calculate_area(intersection_polygons)\n",
    "        total_intersection_area += intersection_area\n",
    "\n",
    "    total_union_area = total_inferred_area + total_original_area - total_intersection_area\n",
    "    iou = total_intersection_area / total_union_area if total_union_area > 0 else 0\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_confidence_thresholds(inference_results, bbox_data, threshold_step=0.02):\n",
    "    # Create a dictionary to store the optimal confidence thresholds for each method\n",
    "    optimal_thresholds = {}\n",
    "\n",
    "    # Iterate over each inference method\n",
    "    for method in inference_results[0].keys():\n",
    "        max_avg_iou = 0\n",
    "        optimal_threshold = 0\n",
    "\n",
    "        # Iterate over different confidence threshold values\n",
    "        for threshold in np.arange(0, 1 + threshold_step, threshold_step):\n",
    "            total_iou = 0\n",
    "            image_count = 0\n",
    "\n",
    "            # Iterate over each inference result\n",
    "            for inference_result in inference_results:\n",
    "                image_file = os.path.basename(inference_result[method][\"image_id\"])\n",
    "\n",
    "                # Find the corresponding bbox data for the image\n",
    "                bbox_data_item = next((data for data in bbox_data if data[\"image_id\"] == image_file), None)\n",
    "\n",
    "                if bbox_data_item is not None:\n",
    "                    # Filter objects based on the current confidence threshold\n",
    "                    filtered_objects = [obj for obj in inference_result[method][\"objects\"] if obj[\"confidence\"] >= threshold]\n",
    "\n",
    "                    # Calculate IoU for the current image\n",
    "                    image_iou = calculate_iou(filtered_objects, bbox_data_item[\"objects\"])\n",
    "                    total_iou += image_iou\n",
    "                    image_count += 1\n",
    "\n",
    "            # Calculate the average IoU for the current threshold\n",
    "            avg_iou = total_iou / image_count if image_count > 0 else 0\n",
    "\n",
    "            # Update the optimal threshold if the current average IoU is higher\n",
    "            if avg_iou > max_avg_iou:\n",
    "                max_avg_iou = avg_iou\n",
    "                optimal_threshold = threshold\n",
    "\n",
    "        # Store the optimal threshold for the current method\n",
    "        optimal_thresholds[method] = round(optimal_threshold, 2)\n",
    "\n",
    "    return optimal_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts class names and calculates optimal confidence thresholds for all images, also loads original bbox data\n",
    "\n",
    "# Load the JSON file containing the bbox data\n",
    "with open(os.path.join(image_folder, \"labels.json\"), \"r\") as file:\n",
    "    original_bbox_data = json.load(file)\n",
    "\n",
    "def convert_class_names_in_results(inference_results, bbox_data):\n",
    "    for inference_result in inference_results:\n",
    "        for method in inference_result:\n",
    "            inference_result[method][\"objects\"] = convert_class_names(inference_result[method][\"objects\"])\n",
    "        \n",
    "        image_file = os.path.basename(inference_result[next(iter(inference_result))][\"image_id\"])\n",
    "        bbox_data_item = next((data for data in bbox_data if data[\"image_id\"] == image_file), None)\n",
    "        \n",
    "        if bbox_data_item is not None:\n",
    "            bbox_data_item[\"objects\"] = convert_class_names(bbox_data_item[\"objects\"])\n",
    "    \n",
    "    return inference_results, bbox_data\n",
    "\n",
    "# Convert class names in the inference results and original data\n",
    "all_inference_results, original_bbox_data = convert_class_names_in_results(all_inference_results, original_bbox_data)\n",
    "\n",
    "optimal_thresholds = find_optimal_confidence_thresholds(all_inference_results, original_bbox_data)\n",
    "print(optimal_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new version of all_inference_results with bboxes below the confidence threshold removed\n",
    "optimized_inference_results = []\n",
    "\n",
    "for inference_result in all_inference_results:\n",
    "    optimized_result = {}\n",
    "    for method in inference_result:\n",
    "        optimal_threshold = optimal_thresholds[method]\n",
    "        \n",
    "        # Filter objects based on the optimal confidence threshold\n",
    "        filtered_objects = [obj for obj in inference_result[method][\"objects\"] if obj[\"confidence\"] >= optimal_threshold]\n",
    "        \n",
    "        # Create a new inference result with the filtered objects\n",
    "        optimized_result[method] = {\n",
    "            \"image_id\": inference_result[method][\"image_id\"],\n",
    "            \"objects\": filtered_objects,\n",
    "            \"inference_time\": inference_result[method][\"inference_time\"],\n",
    "            \"upload_time\": inference_result[method][\"upload_time\"],\n",
    "            #\"image_iou\": inference_result[method][\"image_iou\"]\n",
    "        }\n",
    "    \n",
    "    optimized_inference_results.append(optimized_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates IoU for each image\n",
    "# Iterate over each inference result\n",
    "for inference_result in optimized_inference_results:\n",
    "    # Extract the image name from the inference result\n",
    "    image_file = os.path.basename(inference_result[next(iter(inference_result))][\"image_id\"])\n",
    "    \n",
    "    # Find the corresponding bbox data for the image\n",
    "    bbox_data_item = next((data for data in original_bbox_data if data[\"image_id\"] == image_file), None)\n",
    "    \n",
    "    # Calculate IoU for each inference method\n",
    "    for method in inference_result:\n",
    "        if bbox_data_item is not None:\n",
    "            image_iou = calculate_iou(inference_result[method][\"objects\"], bbox_data_item[\"objects\"])\n",
    "            inference_result[method][\"image_iou\"] = image_iou\n",
    "        else:\n",
    "            print(f\"No corresponding bbox data found for image: {image_file}\")\n",
    "    \n",
    "    # Load and display the image with bounding boxes\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    for method in inference_result:\n",
    "        print(method)\n",
    "        print(\"Inference time:\", inference_result[method][\"inference_time\"], \"ms\")\n",
    "        print(\"IoU: \", inference_result[method][\"image_iou\"])\n",
    "        #draw_bounding_boxes(image_path, inference_result[method][\"objects\"])\n",
    "    \n",
    "    # Display the original image with the original bboxes\n",
    "    print(\"Original Image:\")\n",
    "    #draw_bounding_boxes(image_path, bbox_data_item[\"objects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_results(content):\n",
    "    print(content)\n",
    "    text_file.write(content + \"\\n\")\n",
    "\n",
    "# Get hardware information\n",
    "def get_cpu_info():\n",
    "    cpu_info = cpuinfo.get_cpu_info()\n",
    "    brand = cpu_info['brand_raw']\n",
    "    return brand\n",
    "\n",
    "# Get image resolution\n",
    "image_path = os.path.join(image_folder, optimized_inference_results[0][next(iter(optimized_inference_results[0]))]['image_id'])  # all images have the same resolution\n",
    "image = cv2.imread(image_path)\n",
    "height, width, _ = image.shape\n",
    "image_resolution = f\"{width}x{height}\"\n",
    "\n",
    "# Get hardware information\n",
    "cpu_info = get_cpu_info()\n",
    "ram_info = psutil.virtual_memory()\n",
    "try:\n",
    "    gpu_info = gpustat.new_query()\n",
    "except (ImportError, FileNotFoundError, Exception):\n",
    "    gpu_info = False\n",
    "\n",
    "# Calculate average inference time and image IoU for each method\n",
    "method_metrics = {}\n",
    "for inference_result in optimized_inference_results:\n",
    "    for method in inference_result:\n",
    "        if method not in method_metrics:\n",
    "            method_metrics[method] = {'inference_time': [], 'upload_time': [], 'image_iou': []}\n",
    "        method_metrics[method]['inference_time'].append(float(inference_result[method]['inference_time']))\n",
    "        method_metrics[method]['upload_time'].append(float(inference_result[method]['upload_time']))\n",
    "        method_metrics[method]['image_iou'].append(float(inference_result[method]['image_iou']))\n",
    "\n",
    "for method in method_metrics:\n",
    "    method_metrics[method]['avg_inference_time'] = np.mean(method_metrics[method]['inference_time'])\n",
    "    method_metrics[method]['avg_upload_time'] = np.mean(method_metrics[method]['upload_time'])\n",
    "    method_metrics[method]['avg_image_iou'] = np.mean(method_metrics[method]['image_iou'])\n",
    "\n",
    "# Create a folder with the current datetime as its name\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "folder_name = f\"results_{current_datetime}\"\n",
    "folder_path = os.path.join(output_path, folder_name)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Convert numpy.float32 values to regular float objects\n",
    "all_inference_results = json.loads(json.dumps(all_inference_results, default=lambda x: float(x) if isinstance(x, np.float32) else x))\n",
    "\n",
    "# Save the original all_inference_results data as a JSON file\n",
    "json_file_path = os.path.join(folder_path, \"all_inference_results.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(all_inference_results, json_file, indent=4)\n",
    "\n",
    "# Save the printed information as a text file\n",
    "text_file_path = os.path.join(folder_path, \"results.txt\")\n",
    "with open(text_file_path, \"w\") as text_file:\n",
    "    output_results(\"BATCH INFERENCE\")\n",
    "    output_results(f\"Number of Images Tested: {len(optimized_inference_results)}\")\n",
    "    output_results(f\"Image resolution: {image_resolution}\")\n",
    "    output_results(f\"Dataset used: {dataset_name}\")\n",
    "    output_results(f\"Dataset path: {image_folder}\")\n",
    "    output_results(\"SaaS region/server data:\")\n",
    "    output_results(f\"AWS_REGION: {AWS_REGION}\")\n",
    "    output_results(f\"GOOGLE_PROJECT_ID: {GOOGLE_PROJECT_ID}\")\n",
    "    output_results(f\"MICROSOFT_ENDPOINT: {MICROSOFT_ENDPOINT}\")\n",
    "    output_results(\"Hardware Information:\")\n",
    "    output_results(f\"CPU: {cpu_info}\")\n",
    "    output_results(f\"RAM: {ram_info.total / (1024 * 1024 * 1024):.2f} GB\")\n",
    "    if (gpu_info):\n",
    "        output_results(f\"GPU: {gpu_info.name} - {gpu_info.memory_total / 1024:.2f} GB\")\n",
    "    else:\n",
    "        output_results(\"GPU: N/A\")\n",
    "    output_results(\"Averaged Results:\")\n",
    "    for method, metrics in method_metrics.items():\n",
    "        output_results(f\"{method}:\")\n",
    "        output_results(f\" Average Inference Time: {metrics['avg_inference_time']:.2f} ms\")\n",
    "        output_results(f\" Average Upload Time: {metrics['avg_upload_time']:.2f} ms\")\n",
    "        output_results(f\" Average Image IoU: {metrics['avg_image_iou']:.4f}\")\n",
    "        output_results(f\" Optimal confidence threshold used: {optimal_thresholds[method]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "methods = list(method_metrics.keys())\n",
    "avg_inference_times = [method_metrics[method]['avg_inference_time'] for method in methods]\n",
    "avg_upload_times = [method_metrics[method]['avg_upload_time'] for method in methods]\n",
    "avg_image_ious = [method_metrics[method]['avg_image_iou'] for method in methods]\n",
    "\n",
    "# Create and save the average inference time and upload time plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(methods))\n",
    "plt.bar(x, avg_inference_times, bar_width, label='Inference Time')\n",
    "plt.bar(x, avg_upload_times, bar_width, bottom=avg_inference_times, label='Upload Time')\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Average Inference Time and Upload Time by Method')\n",
    "plt.xticks(x, methods, rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"avg_inference_upload_time.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Create and save the average image IoU plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(methods, avg_image_ious)\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Average Image IoU')\n",
    "plt.title('Average Image IoU by Method')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"avg_image_iou.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Scatter charts showing how the average changes for both inference and accuracy over each inference call\n",
    "inference_times = {method: [] for method in methods}\n",
    "upload_times = {method: [] for method in methods}\n",
    "image_ious = {method: [] for method in methods}\n",
    "\n",
    "for inference_result in optimized_inference_results:\n",
    "    for method in methods:\n",
    "        inference_times[method].append(float(inference_result[method]['inference_time']))\n",
    "        upload_times[method].append(float(inference_result[method]['upload_time']))\n",
    "        image_ious[method].append(float(inference_result[method]['image_iou']))\n",
    "\n",
    "# Combined line and scatter plots for inference time and upload time\n",
    "plt.figure(figsize=(12, 6))\n",
    "for method in methods:\n",
    "    plt.plot(range(1, len(inference_times[method]) + 1), inference_times[method], label=f'{method} - Inference Time')\n",
    "    plt.plot(range(1, len(upload_times[method]) + 1), upload_times[method], label=f'{method} - Upload Time')\n",
    "    plt.scatter(range(1, len(inference_times[method]) + 1), inference_times[method])\n",
    "    plt.scatter(range(1, len(upload_times[method]) + 1), upload_times[method])\n",
    "plt.xlabel('Inference Call')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Inference and Upload Time')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"inference_upload_time.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Combined line and scatter plots for image IoU\n",
    "plt.figure(figsize=(12, 6))\n",
    "for method in methods:\n",
    "    plt.plot(range(1, len(image_ious[method]) + 1), image_ious[method], label=method)\n",
    "    plt.scatter(range(1, len(image_ious[method]) + 1), image_ious[method])\n",
    "plt.xlabel('Inference Call')\n",
    "plt.ylabel('Image IoU')\n",
    "plt.title('Image IoU')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"image_iou.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Histograms to visualize variance of confidence values, inference times, and IoU throughout each inference of image\n",
    "confidence_values = {method: [] for method in methods}\n",
    "inference_times_hist = {method: [] for method in methods}\n",
    "upload_times_hist = {method: [] for method in methods}\n",
    "image_ious_hist = {method: [] for method in methods}\n",
    "\n",
    "for inference_result in optimized_inference_results:\n",
    "    for method in methods:\n",
    "        for obj in inference_result[method]['objects']:\n",
    "            confidence_values[method].append(obj['confidence'])\n",
    "        inference_times_hist[method].append(float(inference_result[method]['inference_time']))\n",
    "        upload_times_hist[method].append(float(inference_result[method]['upload_time']))\n",
    "        image_ious_hist[method].append(float(inference_result[method]['image_iou']))\n",
    "\n",
    "# Confidence Value Distribution\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "for i, method in enumerate(methods):\n",
    "    axs[i].hist(confidence_values[method], bins=np.linspace(0, 1, 21), density=True)\n",
    "    axs[i].set_xlabel('Confidence Value')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].set_title(f'Confidence Value Distribution - {method}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"confidence_value_distribution.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Inference Time Distribution\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "max_inference_time = max(max(times) for times in inference_times_hist.values())\n",
    "bins = np.linspace(0, max_inference_time, 21)\n",
    "for i, method in enumerate(methods):\n",
    "    axs[i].hist(inference_times_hist[method], bins=bins, density=True)\n",
    "    axs[i].hist(upload_times_hist[method], bins=bins, density=True, alpha=0.5, color='r')  # Added upload time histogram\n",
    "    axs[i].set_xlabel('Time (ms)')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].set_title(f'Time Distribution - {method}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"time_distribution.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Image IoU Distribution\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "for i, method in enumerate(methods):\n",
    "    axs[i].hist(image_ious_hist[method], bins=np.linspace(0, 1, 21), density=True)\n",
    "    axs[i].set_xlabel('Image IoU')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].set_title(f'Image IoU Distribution - {method}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(folder_path, \"image_iou_distribution.png\"))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_test_path_image = \"G:\\\\My Drive\\\\Thesis2024\\\\data\\\\train\\\\1478897977253835405_jpg.rf.k1YHtF480ieDxDfcboNr.jpg\"\n",
    "#test_aio = inferenceFromAllSources(single_test_path_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in test_aio:\n",
    "        print(method)\n",
    "        print(\"Inference time:\", test_aio[method][\"inference_time\"], \"ms\")\n",
    "        #print(\"IoU: \", inference_result[method][\"image_iou\"])\n",
    "        draw_bounding_boxes(single_test_path_image, test_aio[method][\"objects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved file\n",
    "# Specify the path to the JSON file containing the saved inference results\n",
    "json_file_path = os.path.join(folder_path, \"all_inference_results.json\")\n",
    "\n",
    "# Read the JSON file and load the data into the all_inference_results variable\n",
    "with open(json_file_path, \"r\") as json_file:\n",
    "    all_inference_results = json.load(json_file)\n",
    "\n",
    "# Print the loaded data to verify it has been read correctly\n",
    "print(\"Loaded data from JSON file:\")\n",
    "print(all_inference_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
